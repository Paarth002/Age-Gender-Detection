{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tuned_SRGAN_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DOXPWjCQWRDV",
        "zEvSecFQWjOr",
        "hdVIFea4W4ml",
        "VoWdEuugdNMv",
        "eFuGVjhgaVWR",
        "NO6zjRG2dvWt",
        "Brxp_Tzc-Zzu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This produces (x4) **video** for a LR video using a fine-tuned Baseline SRGAN\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Download this notebook, upload it on google colab and then execute\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Note that it only works for video frames with number of pixels less than or equal to 76,800, due to OOM error. Hence, if you upload a video of size more than the specified size, it will resize the video and then upsample it\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Upload the input LR **mp4** video and weights, preferably in the '/content/' folder. You can find the weights in the 'SRGAN-Finetuned' folder of this repo.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "It is advisable to connect runtime to standard GPU\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is a SISR technique, hence it will upsample single image frame at a time. This makes it a bit slower and limits the input size"
      ],
      "metadata": {
        "id": "lTYgfmzxaoAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "DOXPWjCQWRDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import math\n",
        "import cv2 \n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from keras.preprocessing.image import save_img\n",
        "from tensorflow.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, PReLU, Lambda\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "xvFbnBqECPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining function to load images"
      ],
      "metadata": {
        "id": "zEvSecFQWjOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "    return np.array(Image.open(path))"
      ],
      "metadata": {
        "id": "7pkP45HFMkni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the SRGAN model "
      ],
      "metadata": {
        "id": "hdVIFea4W4ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resolve(model, LR_batch):\n",
        "    LR_batch = tf.cast(LR_batch, tf.float32)\n",
        "    SR_batch = model(LR_batch)\n",
        "    SR_batch = tf.clip_by_value(SR_batch, 0, 255)\n",
        "    SR_batch = tf.round(SR_batch)\n",
        "    SR_batch = tf.cast(SR_batch, tf.uint8)\n",
        "    return SR_batch\n",
        "\n",
        "def single_resolve(model, LR):\n",
        "    return resolve(model, tf.expand_dims(LR, axis=0))[0]\n",
        "\n",
        "def pixelshuffler(scale):\n",
        "    return lambda X: tf.nn.depth_to_space(X, scale)"
      ],
      "metadata": {
        "id": "wavmIKrDMYci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_01(X):\n",
        "    return X / 255.0\n",
        "\n",
        "def normalize_m11(X):\n",
        "    return X / 127.5 - 1\n",
        "\n",
        "def denormalize_m11(X):\n",
        "    return (X + 1) * 127.5"
      ],
      "metadata": {
        "id": "Em9sukKiXdWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Resnetblock(X_input, num_filters, momentum=0.8):\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X_input)\n",
        "    X = BatchNormalization(momentum=momentum)(X)\n",
        "    X = PReLU(shared_axes=[1, 2])(X)\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X)\n",
        "    X = BatchNormalization(momentum=momentum)(X)\n",
        "    X = Add()([X_input, X])\n",
        "    return X\n",
        "\n",
        "def Upsample(X_input, num_filters):\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X_input)\n",
        "    X = Lambda(pixelshuffler(scale=2))(X)\n",
        "    return PReLU(shared_axes=[1, 2])(X)\n",
        "\n",
        "def Generator(num_filters=64, num_of_resnet_blocks=16):\n",
        "    X_in = Input(shape=(None, None, 3))\n",
        "    X = Lambda(normalize_01)(X_in)\n",
        "\n",
        "    X = Conv2D(num_filters, kernel_size=9, padding='same')(X)\n",
        "    X = X_1 = PReLU(shared_axes=[1, 2])(X)\n",
        "\n",
        "    for _ in range(num_of_resnet_blocks):\n",
        "        X = Resnetblock(X, num_filters)\n",
        "\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Add()([X_1, X])\n",
        "\n",
        "    X = Upsample(X, num_filters * 4)\n",
        "    X = Upsample(X, num_filters * 4)\n",
        "\n",
        "    X = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(X)\n",
        "    X = Lambda(denormalize_m11)(X)\n",
        "\n",
        "    return Model(X_in, X)\n",
        "\n",
        "SRGAN = Generator"
      ],
      "metadata": {
        "id": "8t-7___CBrS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiating the generator\n",
        "Add the path to the weights file as an argument(str) to the load_weights() function in the following hidden cell"
      ],
      "metadata": {
        "id": "VoWdEuugdNMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRGAN_model = SRGAN()\n",
        "SRGAN_model.load_weights('/content/ganweight(after 26k epochs).h5') #copy the path of our .h5 weights file and past it here"
      ],
      "metadata": {
        "id": "D7mRPvsv4rPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the function to apply SRGAN on video\n"
      ],
      "metadata": {
        "id": "eFuGVjhgaVWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_resizer(orig_vid_path, fps_, h, w): \n",
        "\n",
        "  cap = cv2.VideoCapture(orig_vid_path)\n",
        "  A = 76800\n",
        "  if (h>w):\n",
        "    r = (h/w)\n",
        "    new_w = int(math.sqrt(A/r))\n",
        "    new_h = int(math.sqrt(A*r))\n",
        "  else :\n",
        "    r = (w/h)\n",
        "    new_h = int(math.sqrt(A/r))\n",
        "    new_w = int(math.sqrt(A*r))\n",
        "  \n",
        "  print(\"resized height=\", new_h, \"and resized width=\", new_w)\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "  out = cv2.VideoWriter('/content/input_video_resized.mp4',fourcc, fps_, (new_w,new_h))\n",
        "  \n",
        "  while True:\n",
        "      ret, frame = cap.read()\n",
        "      if ret == True:\n",
        "          b = cv2.resize(frame,(new_w,new_h),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
        "          out.write(b)\n",
        "      else:\n",
        "          break\n",
        "      \n",
        "  cap.release()\n",
        "  out.release()"
      ],
      "metadata": {
        "id": "FGjEn4FyhLxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SRGAN_on_video(vid_path, kps):\n",
        "\n",
        "  video = cv2.VideoCapture(vid_path)\n",
        "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "  if int(major_ver)  < 3 :\n",
        "    fps = int(video.get(cv2.cv.CV_CAP_PROP_FPS))\n",
        "  else :\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "  if (fps == 0): \n",
        "    print('pls upload a different video')\n",
        "    quit()\n",
        "\n",
        "  print(fps)\n",
        "\n",
        "  hop = round(fps/kps)\n",
        "  if hop == 0:\n",
        "    print('pls select such custom fps such that fps<=',fps)\n",
        "    quit()\n",
        "\n",
        "  h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  \n",
        "  print(\"orig height=\", h, \"and orig width=\", w)\n",
        "  if (h*w > 76800):\n",
        "    video_resizer(vid_path, fps, h, w)\n",
        "    video = cv2.VideoCapture('/content/input_video_resized.mp4')\n",
        "\n",
        "  arr_output_names = []\n",
        "\n",
        "  frames_dir = '/content/framesdir'\n",
        "  os.makedirs(frames_dir)\n",
        "  output_dir = '/content/outframes'\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "  currentframe = 0       \n",
        "\n",
        "  while(True):\n",
        "      ret,frame = video.read()\n",
        "      if ret:\n",
        "        if (currentframe % hop == 0):\n",
        "          name = frames_dir + '/' + str(int(currentframe/hop)) + '.jpg'\n",
        "          cv2.imwrite(name, frame) \n",
        "          LR = load_image(name)\n",
        "          SR = single_resolve(SRGAN_model, LR)\n",
        "          img_pil = array_to_img(SR)\n",
        "          out_name = output_dir + '/' + str(int(currentframe/hop)) + '.jpg'\n",
        "          img = save_img(out_name, img_pil)\n",
        "          arr_output_names.append(out_name)\n",
        "        currentframe += 1\n",
        "      else:\n",
        "        break\n",
        "\n",
        "  video.release()\n",
        "\n",
        "  image = cv2.imread(output_dir + '/0.jpg')\n",
        "  height, width, layers = image.shape\n",
        "\n",
        "  size = (width,height)\n",
        "\n",
        "  out = cv2.VideoWriter('/content/finetuned_SRGAN_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), kps , size)\n",
        "\n",
        "  for i in range(len(arr_output_names)):\n",
        "    out.write(cv2.imread(arr_output_names[i]))\n",
        "  out.release()\n"
      ],
      "metadata": {
        "id": "Um6sbMoQgC0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the fine-tuned generator on your video\n",
        "Add the path(str) to your custom video and frame rate per second (int and <30) as arguments to the SRGAN_on_video() function given in the below cell\n",
        "\n",
        "The output video will be saved as '/content/finetuned_SRGAN_output.mp4' and you can find the input resized video (if any) as '/content/input_video_resized.mp4'"
      ],
      "metadata": {
        "id": "NO6zjRG2dvWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRGAN_on_video(\"/content/CCTV.mp4\", 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "Bm5HOz5BK02k",
        "outputId": "b89c4b51-e681-4a78-d67b-58811a084d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "orig height= 1080 and orig width= 1920\n",
            "resized height= 207 and resized width= 369\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-af3a581fc3cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSRGAN_on_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/CCTV.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-5e1b553cd27c>\u001b[0m in \u001b[0;36mSRGAN_on_video\u001b[0;34m(vid_path, kps)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"orig height=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"and orig width=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m76800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mvideo_resizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/input_video_resized.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-19b594248d19>\u001b[0m in \u001b[0;36mvideo_resizer\u001b[0;34m(orig_vid_path, fps_, h, w)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing the stored input and output frames"
      ],
      "metadata": {
        "id": "Brxp_Tzc-Zzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image in os.listdir('/content/framesdir'):\n",
        "  os.remove('/content/framesdir' + '/' + image)\n",
        "os.rmdir('/content/framesdir')\n",
        "for image in os.listdir('/content/outframes'):\n",
        "  os.remove('/content/outframes' + '/' + image)\n",
        "os.rmdir('/content/outframes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "3WjBu8NgysmK",
        "outputId": "d297a96d-024e-4617-f720-bb9f7eccae5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5a453e2ff3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/framesdir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/framesdir'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/framesdir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/outframes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/outframes'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/framesdir'"
          ]
        }
      ]
    }
  ]
}