{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuned-SRGAN_img_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zEvSecFQWjOr",
        "hdVIFea4W4ml",
        "VoWdEuugdNMv",
        "eFuGVjhgaVWR",
        "NO6zjRG2dvWt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This produces (x4) **image** for a LR image using a fine-tuned Baseline SRGAN\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Download this notebook, upload it on google colab and then execute\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Note that it only works for image with number of pixels less than or equal to 76,800, due to OOM error. Hence, if you upload an image of size more than the specified size, it will resize the image and then upsample it\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Upload the input LR **.jpg** image and weights, preferably in the '/content/' folder. You can find the weights in the 'SRGAN-Finetuned' folder of this repo.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "It is advisable to connect runtime to standard GPU\n"
      ],
      "metadata": {
        "id": "lTYgfmzxaoAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "DOXPWjCQWRDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import math\n",
        "import cv2 \n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from keras.preprocessing.image import save_img\n",
        "from tensorflow.keras.layers import Add, BatchNormalization, Conv2D, Dense, Flatten, Input, PReLU, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from PIL import Image \n",
        "import PIL "
      ],
      "metadata": {
        "id": "xvFbnBqECPfk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining function to load images"
      ],
      "metadata": {
        "id": "zEvSecFQWjOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "    return np.array(Image.open(path))"
      ],
      "metadata": {
        "id": "7pkP45HFMkni"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the SRGAN model "
      ],
      "metadata": {
        "id": "hdVIFea4W4ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resolve(model, LR_batch):\n",
        "    LR_batch = tf.cast(LR_batch, tf.float32)\n",
        "    SR_batch = model(LR_batch)\n",
        "    SR_batch = tf.clip_by_value(SR_batch, 0, 255)\n",
        "    SR_batch = tf.round(SR_batch)\n",
        "    SR_batch = tf.cast(SR_batch, tf.uint8)\n",
        "    return SR_batch\n",
        "\n",
        "def single_resolve(model, LR):\n",
        "    return resolve(model, tf.expand_dims(LR, axis=0))[0]\n",
        "\n",
        "def pixelshuffler(scale):\n",
        "    return lambda X: tf.nn.depth_to_space(X, scale)"
      ],
      "metadata": {
        "id": "wavmIKrDMYci"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_01(X):\n",
        "    return X / 255.0\n",
        "\n",
        "def normalize_m11(X):\n",
        "    return X / 127.5 - 1\n",
        "\n",
        "def denormalize_m11(X):\n",
        "    return (X + 1) * 127.5"
      ],
      "metadata": {
        "id": "Em9sukKiXdWl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Resnetblock(X_input, num_filters, momentum=0.8):\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X_input)\n",
        "    X = BatchNormalization(momentum=momentum)(X)\n",
        "    X = PReLU(shared_axes=[1, 2])(X)\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X)\n",
        "    X = BatchNormalization(momentum=momentum)(X)\n",
        "    X = Add()([X_input, X])\n",
        "    return X\n",
        "\n",
        "def Upsample(X_input, num_filters):\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X_input)\n",
        "    X = Lambda(pixelshuffler(scale=2))(X)\n",
        "    return PReLU(shared_axes=[1, 2])(X)\n",
        "\n",
        "def Generator(num_filters=64, num_of_resnet_blocks=16):\n",
        "    X_in = Input(shape=(None, None, 3))\n",
        "    X = Lambda(normalize_01)(X_in)\n",
        "\n",
        "    X = Conv2D(num_filters, kernel_size=9, padding='same')(X)\n",
        "    X = X_1 = PReLU(shared_axes=[1, 2])(X)\n",
        "\n",
        "    for _ in range(num_of_resnet_blocks):\n",
        "        X = Resnetblock(X, num_filters)\n",
        "\n",
        "    X = Conv2D(num_filters, kernel_size=3, padding='same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Add()([X_1, X])\n",
        "\n",
        "    X = Upsample(X, num_filters * 4)\n",
        "    X = Upsample(X, num_filters * 4)\n",
        "\n",
        "    X = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(X)\n",
        "    X = Lambda(denormalize_m11)(X)\n",
        "\n",
        "    return Model(X_in, X)\n",
        "\n",
        "SRGAN = Generator"
      ],
      "metadata": {
        "id": "8t-7___CBrS3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiating the generator\n",
        "Add the path to the weights file as an argument(str) to the load_weights() function in the following hidden cell"
      ],
      "metadata": {
        "id": "VoWdEuugdNMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRGAN_model = SRGAN()\n",
        "SRGAN_model.load_weights('/content/ganweight(after 26k epochs).h5') #copy the path of our .h5 weights file and past it here"
      ],
      "metadata": {
        "id": "D7mRPvsv4rPS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the function to apply SRGAN on image\n"
      ],
      "metadata": {
        "id": "eFuGVjhgaVWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_resizer(orig_img_path, h, w): \n",
        "\n",
        "  orig_img = cv2.imread(orig_img_path)\n",
        "  A = 76800\n",
        "  if (h>w):\n",
        "    r = (h/w)\n",
        "    new_w = int(math.sqrt(A/r))\n",
        "    new_h = int(math.sqrt(A*r))\n",
        "  else :\n",
        "    r = (w/h)\n",
        "    new_h = int(math.sqrt(A/r))\n",
        "    new_w = int(math.sqrt(A*r))\n",
        "  \n",
        "  print(\"resized height=\", new_h, \"and resized width=\", new_w)\n",
        "\n",
        "  out = cv2.resize(orig_img, (new_w,new_h))\n",
        "\n",
        "  cv2.imwrite('/content/input_img_resized.jpg', out)"
      ],
      "metadata": {
        "id": "FGjEn4FyhLxV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SRGAN_on_img(img_path):\n",
        "\n",
        "  input = cv2.imread(img_path)\n",
        "\n",
        "  h = input.shape[0]\n",
        "  w = input.shape[1]\n",
        "  \n",
        "  print(\"orig height=\", h, \"and orig width=\", w)\n",
        "  if (h*w > 76800):\n",
        "    img_resizer(img_path, h, w)\n",
        "    input = cv2.imread('/content/input_img_resized.jpg')\n",
        "\n",
        "  sr = single_resolve(SRGAN_model, input)\n",
        "  out_name = '/content/finetuneSRGANoutput.png' \n",
        "  img_pil = array_to_img(sr)\n",
        "  img1 = save_img(out_name, img_pil)"
      ],
      "metadata": {
        "id": "Um6sbMoQgC0I"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the fine-tuned generator on your image\n",
        "Add the path(str) to your custom image as argument to the SRGAN_on_img() function given in the below cell\n",
        "\n",
        "The output image will be saved as '/content/finetuneSRGANoutput.png'  and you can find the input resized image (if any) as '/content/input_img_resized.jpg'"
      ],
      "metadata": {
        "id": "NO6zjRG2dvWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRGAN_on_img(\"/content/low_resolution_img.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm5HOz5BK02k",
        "outputId": "62c4789a-68a2-4cd4-c809-df65a29fb132"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig height= 841 and orig width= 1327\n",
            "resized height= 220 and resized width= 348\n"
          ]
        }
      ]
    }
  ]
}